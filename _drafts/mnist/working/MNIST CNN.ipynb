{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Split the provided training data to create a new training \n",
    "data set and a new validation data set. These will be used\n",
    "or hyper-parameter tuning.\n",
    "'''\n",
    "\n",
    "# For reproducibility\n",
    "seed = 27\n",
    "\n",
    "raw_data = pd.read_csv(\"../input/train.csv\")\n",
    "\n",
    "train, validate = train_test_split(raw_data, test_size=0.1, random_state = seed, stratify = raw_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into input (X) and output (Y) variables\n",
    "x_train = train.values[:,1:]\n",
    "y_train = train.values[:,0]\n",
    "\n",
    "x_validate = validate.values[:,1:]\n",
    "y_validate = validate.values[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/everett/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (37800, 28, 28, 1)\n",
      "37800 train samples\n",
      "4200 validation samples\n",
      "Epoch 1/32\n",
      "  43/1181 [>.............................] - ETA: 2:56 - loss: 1.8961 - acc: 0.3377"
     ]
    }
   ],
   "source": [
    "'''Trains a convnet on the MNIST dataset.\n",
    "\n",
    "Gets to 99.65% test accuracy after 20 epochs\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 512\n",
    "num_classes = 10\n",
    "epochs = 32\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_validate = x_validate.reshape(x_validate.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_validate = x_validate.reshape(x_validate.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_validate = x_validate.astype('float32')\n",
    "x_train /= 255\n",
    "x_validate /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_validate.shape[0], 'validation samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_validate = keras.utils.to_categorical(y_validate, num_classes)\n",
    "\n",
    "# Use the built in data generation features of Keras\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range = 0.075,\n",
    "    height_shift_range = 0.075,\n",
    "    rotation_range = 12,\n",
    "    shear_range = 0.075,\n",
    "    zoom_range = 0.05,\n",
    "    fill_mode = 'constant',\n",
    "    cval = 0\n",
    ")\n",
    "\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "          \n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "          \n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    " \n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5,\n",
    "                              patience = 2, min_lr = 0.0001)\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train, \n",
    "                                  y_train, \n",
    "                                  batch_size = batch_size), \n",
    "                    epochs = epochs,\n",
    "                    steps_per_epoch = x_train.shape[0]/32,\n",
    "                    verbose = 1,\n",
    "                    validation_data = (x_validate, y_validate),\n",
    "                    callbacks = [reduce_lr])\n",
    "\n",
    "score = model.evaluate(x_validate, y_validate, verbose = 0)\n",
    "print('Validation loss:', score[0])\n",
    "print('Validation accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "test = pd.read_csv(\"../input/test.csv\").values[:,:]\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    test = test.reshape(test.shape[0], 1, img_rows, img_cols)\n",
    "else:\n",
    "    test = test.reshape(test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "test = test.astype('float32')\n",
    "test /= 255\n",
    "\n",
    "pred = np.argmax(model.predict(test), axis = 1)\n",
    "submission = pd.DataFrame(data = pred, columns = ['Label'])\n",
    "submission['ImageId'] = submission.index + 1\n",
    "submission = submission[['ImageId', 'Label']]\n",
    "\n",
    "submission.to_csv(\"submissions/Jan-13-2018.csv\", index = False)\n",
    "model.save(\"models/Jan-13-2018.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
