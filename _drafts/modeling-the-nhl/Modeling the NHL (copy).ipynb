{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally I wanted to adapt a model for predicting NCAA basket ball outcomes to the NHL. The model is called [Bayesian Logistic Regression Markov Chain (LRMC)](https://www2.isye.gatech.edu/~jsokol/lrmc/) and it works by treating the difference in points between two teams in any game as a normally distributed random variable which depends on the inherent difference in skill between the two teams plus a home court advantage added to the home team. The home court advantage is assumed to be constant across all teams. Unfortunately, when I originally explored this idea I discovered that the difference in score between two teams in each game would not be a good fit for a normal distribution, and so I concluded there wouldn't be an easy way to fit the LRMC model to the NHL.\n",
    "\n",
    "Refusing to give up on this project, I started looking at other ways to model HHL games, and thought about trying to model them in PYMC3. This thought lead me to a PYMC3 example called [A Hierarchical model for Rugby prediction](https://docs.pymc.io/notebooks/rugby_analytics.html) by Peadar Coyle. That work was inspired by [Daniel Weitzenfeld](http://danielweitzenfeld.github.io/passtheroc/blog/2014/10/28/bayes-premier-league/), which in turn was based on a model first developed by [Gianluca Baio and Marta A. Blangiardo](http://www.statistica.it/gianluca/Research/BaioBlangiardo.pdf). With the help of the above examples and papers, I was able to figure out the preceding models and adapt them to the NHL. Due to NHL rules which force a winner of every game by first going to a five minute sudden death overtime, and then to a shootout, I have also extended the model to calculate a tie-breaker random variable to determine the ultimate winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/everett/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Import all of the libraries needed for this post\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "import theano\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can dive into creating the model, we need to get some data. The functions below use the requests and json libraries to extract the data we need from the official NHL statistics API. I have written the data to CSV file so that it is possible to perform the rest of the analysis without constantly retrieving the data over the Internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# A function that retrieves the game data from the NHL stats API\n",
    "# for a selected date range.\n",
    "def request_game_data(start_date, end_date):\n",
    "    base_url = 'https://statsapi.web.nhl.com'\n",
    "    path = '/api/v1/schedule?startDate='+start_date+\\\n",
    "            '&endDate='+end_date+'&expand=schedule.linescore'\n",
    "    response = requests.get(base_url + path)\n",
    "    return response.json()\n",
    "\n",
    "# A function to extract the relevant data from the schedule\n",
    "# and return it as a pandas dataframe\n",
    "def extract_game_data(schedule):\n",
    "    \"\"\"Given full JSON records for games from the NHL API,\n",
    "    returns a simplified list of just the data we need.\n",
    "    \"\"\"\n",
    "    games = pd.DataFrame(columns=['date',\n",
    "                                  'season',\n",
    "                                  'game_type',\n",
    "                                  'home_team',\n",
    "                                  'home_team_reg_score',\n",
    "                                  'home_team_fin_score',\n",
    "                                  'away_team',\n",
    "                                  'away_team_reg_score',\n",
    "                                  'away_team_fin_score',\n",
    "                                  'went_to_shoot_out'\n",
    "                                  ])\n",
    "\n",
    "    for date_obj in schedule['dates']:\n",
    "        date = date_obj['date'];\n",
    "        for game_obj in date_obj['games']:\n",
    "            game_type = game_obj['gameType']\n",
    "            season = game_obj['season']\n",
    "            home_team_obj = game_obj['teams']['home']\n",
    "            away_team_obj = game_obj['teams']['away']\n",
    "\n",
    "            home_team = home_team_obj['team']['name']\n",
    "            home_team_fin_score = home_team_obj['score']\n",
    "\n",
    "            away_team = away_team_obj['team']['name']\n",
    "            away_team_fin_score = away_team_obj['score']\n",
    "\n",
    "            detailed_score_data = game_obj['linescore']\n",
    "            period_data = detailed_score_data['periods']\n",
    "            shootout_data = detailed_score_data['shootoutInfo']\n",
    "\n",
    "            home_team_reg_score = 0\n",
    "            away_team_reg_score = 0\n",
    "\n",
    "            for period in period_data[0:3]:\n",
    "                home_team_reg_score += period['home']['goals']\n",
    "                away_team_reg_score += period['away']['goals']\n",
    "\n",
    "            went_to_shoot_out = (shootout_data['home']['attempts'] != 0 or\n",
    "                                 shootout_data['away']['attempts'] != 0)\n",
    "\n",
    "            games = games.append({'date': date,\n",
    "                                  'season': season,\n",
    "                                  'game_type': game_type,\n",
    "                                  'home_team': home_team,\n",
    "                                  'home_team_reg_score': home_team_reg_score,\n",
    "                                  'home_team_fin_score': home_team_fin_score,\n",
    "                                  'away_team': away_team,\n",
    "                                  'away_team_reg_score': away_team_reg_score,\n",
    "                                  'away_team_fin_score': away_team_fin_score,\n",
    "                                  'went_to_shoot_out': went_to_shoot_out\n",
    "                                  }, ignore_index=True)\n",
    "\n",
    "    return games\n",
    "\n",
    "completed_game_data = request_game_data('2018-02-24', '2019-02-24')\n",
    "completed_games = extract_game_data(completed_game_data)\n",
    "completed_games.to_csv('completed_games.csv', index = False)\n",
    "\n",
    "scheduled_game_data = request_game_data('2019-02-25', '2019-04-09')\n",
    "scheduled_games = extract_game_data(scheduled_game_data)\n",
    "scheduled_games.to_csv('scheduled_games.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is necessary to also decorate this data with integer labels for the home and away teams, as well as the team pairs. These labels serve as an array index for the random variables, and allow us to reference the correct random variables for each team or team pair in the PYMC3 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data to just regular season games from the 2015-2016 and \n",
    "# 2016-2017 seasons \n",
    "completed_games = pd.read_csv('completed_games.csv')\n",
    "completed_games = completed_games.loc[completed_games['game_type'] == 'R']\n",
    "\n",
    "# Select the columns I need for this analysis\n",
    "completed_games = completed_games[['home_team', 'away_team', \n",
    "                                   'home_team_reg_score', \n",
    "                                   'away_team_reg_score', \n",
    "                                   'home_team_fin_score', \n",
    "                                   'away_team_fin_score']]\n",
    "\n",
    "# Extract the unique list of teams and assign an integer label to each one\n",
    "teams = completed_games.home_team.unique()\n",
    "teams = np.sort(teams)\n",
    "teams = pd.DataFrame(teams, columns=['team'])\n",
    "teams['i'] = teams.index\n",
    "\n",
    "# Create a unique list of each team combination and assign an integer label\n",
    "# to each one. Also decide which team will be 'heads' in each pair.\n",
    "all_teams_pair_combinations = combinations(teams['team'], 2)\n",
    "team_pairs_dict = {}\n",
    "team_pairs_heads_dict = {}\n",
    "pair_index = 0\n",
    "for pair in all_teams_pair_combinations:\n",
    "    team_pairs_dict[(pair[0], pair[1])] = pair_index\n",
    "    team_pairs_dict[(pair[1], pair[0])] = pair_index\n",
    "    team_pairs_heads_dict[(pair[0], pair[1])] = pair[0]\n",
    "    team_pairs_heads_dict[(pair[1], pair[0])] = pair[0]\n",
    "    pair_index += 1\n",
    "    \n",
    "# Determine if the ultimate winner of the game was the heads team \n",
    "# (Bernoulli outcome = True) or the tails team (Bernoulli outcome = False)\n",
    "def game_outcome_to_bernoulli_data(row):\n",
    "    if row['home_team_fin_score'] > row['away_team_fin_score']:\n",
    "        return row['home_team'] == team_pairs_heads_dict[(row['home_team'], row['away_team'])]\n",
    "    return row['away_team'] == team_pairs_heads_dict[(row['home_team'], row['away_team'])]\n",
    "\n",
    "# Modify the data to include team and pair integer labels\n",
    "def add_team_data_labels(game_data):\n",
    "    game_data = game_data.merge(teams, left_on='home_team', right_on='team', how='left')\n",
    "    game_data = game_data.rename(columns={'i': 'i_home'}).drop('team', axis=1)\n",
    "    game_data = game_data.merge(teams, left_on='away_team', right_on='team', how='left')\n",
    "    game_data = game_data.rename(columns={'i': 'i_away'}).drop('team', axis=1)\n",
    "    game_data['i_pair'] = game_data.apply(lambda row: team_pairs_dict[(row['home_team'], row['away_team'])], axis=1)  \n",
    "    game_data['i_pair_winner'] = game_data.apply(game_outcome_to_bernoulli_data, axis=1)\n",
    "    \n",
    "    return game_data\n",
    "    \n",
    "completed_games = add_team_data_labels(completed_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the ultimate goal of this model is to make predictions about the outcomes for games that haven't been played yet we need to extract the data for the model into Theano shared variables as [described in the PYMC3 documentation](https://docs.pymc.io/advanced_theano.html). This will allow us to swap out the data for completed games with the scheduled games and then predict samples of game outcomes for those scheduled games too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the total number of teams and team pairs for PYMC3\n",
    "num_teams = len(completed_games.i_home.drop_duplicates())\n",
    "num_team_pairs  = len(completed_games.i_pair.drop_duplicates())\n",
    "\n",
    "# Create shaed theano variables that can be swapped out with\n",
    "# scheduled games later.\n",
    "home_team = theano.shared(completed_games.i_home.values)\n",
    "away_team = theano.shared(completed_games.i_away.values)\n",
    "team_pair = theano.shared(completed_games.i_pair.values)\n",
    "\n",
    "# Create arrays of observations for our pymc3 model\n",
    "observed_home_goals = completed_games.home_team_reg_score.values\n",
    "observed_away_goals = completed_games.away_team_reg_score.values\n",
    "observed_pair_outcomes = completed_games.i_pair_winner.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit the PYMC3 model. The model assumes that goals scored in regulation time by the home and the away team can be modeled as Poisson distributed random variables, which we treat as observed random variables since we can see the number of goals that were scored. We also assume that the distribution of these variables is dependent on some inherent features of the teams such as their defensive and offensive skill, as well as other phenomenon not specific to teams such as home ice advantage and a constant intercept term. All of these are unobserved random variables that we expect to determine the Poisson distributions for goals scored in each game. Additionally, the tie breaker is modeled as a Bernoulli observed random variable which I have opted to define using a Beta distribution as the unobserved random variable that determines the probability of a success. This Bernoulli random varable does not consider home ice advantage, as we determined in my last post that it does not play a major role in deciding the winner after a game makes it to overtime or a shootout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 464 is out of bounds for size 461",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a42762b9b58d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mhome_goals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPoisson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'home_goals'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhome_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserved_home_goals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0maway_goals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPoisson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'away_goals'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maway_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserved_away_goals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtie_breaker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBernoulli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tie_breaker'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbernoulli_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mteam_pair\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserved_pair_outcomes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/bayes_bet/lib/python3.6/site-packages/theano/tensor/var.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    568\u001b[0m                             \u001b[0mTensorVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorConstant\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                             theano.tensor.sharedvar.TensorSharedVariable))):\n\u001b[0;32m--> 570\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvanced_subtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayes_bet/lib/python3.6/site-packages/theano/tensor/var.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, mode)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[0;31m# COPYING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayes_bet/lib/python3.6/site-packages/theano/tensor/subtensor.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(a, indices, axis, mode)\u001b[0m\n\u001b[1;32m   2448\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0madvanced_subtensor1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2450\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0madvanced_subtensor1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2452\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayes_bet/lib/python3.6/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m                 \u001b[0mthunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m                 \u001b[0mrequired\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrequired\u001b[0m  \u001b[0;31m# We provided all inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayes_bet/lib/python3.6/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m()\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m             \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayes_bet/lib/python3.6/site-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayes_bet/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 464 is out of bounds for size 461"
     ]
    }
   ],
   "source": [
    "with pm.Model() as model:\n",
    "    # Global model parameters\n",
    "    home = pm.Flat('home')\n",
    "    sd_offence = pm.HalfStudentT('sd_offence', nu=3, sd=2.5)\n",
    "    sd_defence = pm.HalfStudentT('sd_defence', nu=3, sd=2.5)\n",
    "    intercept = pm.Flat('intercept')\n",
    "\n",
    "    # Team-specific poisson model parameters\n",
    "    offence_star = pm.Normal('offence_star', mu=0, sd=sd_offence, shape=num_teams)\n",
    "    defence_star = pm.Normal('defence_star', mu=0, sd=sd_defence, shape=num_teams)\n",
    "    offence = pm.Deterministic('offence', offence_star - tt.mean(offence_star))\n",
    "    defence = pm.Deterministic('defence', defence_star - tt.mean(defence_star))\n",
    "    home_theta = tt.exp(intercept + home + offence[home_team] - defence[away_team])\n",
    "    away_theta = tt.exp(intercept + offence[away_team] - defence[home_team])\n",
    "\n",
    "    # Team-pair bernoulli model parameters\n",
    "    beta_a = np.array([1] * num_team_pairs)\n",
    "    beta_b = np.array([1] * num_team_pairs)\n",
    "    bernoulli_p = pm.Beta('binom_p', alpha=beta_a, beta=beta_b, shape=num_team_pairs)\n",
    "    \n",
    "    # Likelihood of observed data\n",
    "    home_goals = pm.Poisson('home_goals', mu=home_theta, observed=observed_home_goals)\n",
    "    away_goals = pm.Poisson('away_goals', mu=away_theta, observed=observed_away_goals)\n",
    "    tie_breaker = pm.Bernoulli('tie_breaker', p=bernoulli_p[team_pair], observed=observed_pair_outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    trace = pm.sample(2000, tune=1000, cores=3)\n",
    "    pm.traceplot(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trace plots make it appear as though the PYMC3 model has converged to the stationary distribution for each of the variables, suggesting that we do not need to adjust the burn-in period manually.\n",
    "\n",
    "Next we can also look at the BFMI and Gelman-Rubin statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfmi = pm.bfmi(trace)\n",
    "max_gr = max(np.max(gr_stats) for gr_stats in pm.gelman_rubin(trace).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pm.energyplot(trace, legend=False, figsize=(6, 4))\n",
    "   .set_title(\"BFMI = {}\\nGelman-Rubin = {}\".format(bfmi, max_gr)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [BFMI statistic is well above the threshold of 0.2](https://docs.pymc.io/api/stats.html) that is typically suggested by the PYMC3 and Stan projects for indicating poor sampling. Furthermore, the Gelman-Rubin statistic is very close to 1, which further suggests that convergence on the stationary distribution has occurred.\n",
    "\n",
    "Satisfied that the PYMC3 model hasn't failed miserably, let's look at the posterior distributions for some of the unobserved random variables like team offensive and defensive strengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "df_hpd = pd.DataFrame(pm.stats.hpd(trace['offence']),\n",
    "                      columns=['hpd_low', 'hpd_high'],\n",
    "                      index=teams.team.values)\n",
    "df_median = pd.DataFrame(pm.stats.quantiles(trace['offence'])[50],\n",
    "                         columns=['hpd_median'],\n",
    "                         index=teams.team.values)\n",
    "df_hpd = df_hpd.join(df_median)\n",
    "df_hpd['relative_lower'] = df_hpd.hpd_median - df_hpd.hpd_low\n",
    "df_hpd['relative_upper'] = df_hpd.hpd_high - df_hpd.hpd_median\n",
    "df_hpd = df_hpd.sort_values(by='hpd_median')\n",
    "df_hpd = df_hpd.reset_index()\n",
    "df_hpd['x'] = df_hpd.index + .5\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(10,4))\n",
    "axs.errorbar(df_hpd.x, df_hpd.hpd_median,\n",
    "             yerr=(df_hpd[['relative_lower', 'relative_upper']].values).T,\n",
    "             fmt='o')\n",
    "axs.set_title('HPD of Offensive Strength by Team')\n",
    "axs.set_xlabel('Team')\n",
    "axs.set_ylabel('Posterior Offensive Strength')\n",
    "_= axs.set_xticks(df_hpd.index + .5)\n",
    "_= axs.set_xticklabels(df_hpd['index'].values, rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spread of offensive strengths looks pretty reasonable, and it seems to rank the teams well based on what little I know about their ability to score goals. Note that the Vegas Golden Knights have a slightly wider Highest Posterior Density (HPD) interval than the other teams. This makes sense since they have only started playing in the current recent season, and have far fewer games than the rest of the teams since we have included the complete 2016-2017 season in the data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hpd = pd.DataFrame(pm.stats.hpd(trace['defence']),\n",
    "                      columns=['hpd_low', 'hpd_high'],\n",
    "                      index=teams.team.values)\n",
    "df_median = pd.DataFrame(pm.stats.quantiles(trace['defence'])[50],\n",
    "                         columns=['hpd_median'],\n",
    "                         index=teams.team.values)\n",
    "df_hpd = df_hpd.join(df_median)\n",
    "df_hpd['relative_lower'] = df_hpd.hpd_median - df_hpd.hpd_low\n",
    "df_hpd['relative_upper'] = df_hpd.hpd_high - df_hpd.hpd_median\n",
    "df_hpd = df_hpd.sort_values(by='hpd_median')\n",
    "df_hpd = df_hpd.reset_index()\n",
    "df_hpd['x'] = df_hpd.index + .5\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(10,4))\n",
    "axs.errorbar(df_hpd.x, df_hpd.hpd_median,\n",
    "             yerr=(df_hpd[['relative_lower', 'relative_upper']].values).T,\n",
    "             fmt='o')\n",
    "axs.set_title('HPD of Defensive Strength, by Team')\n",
    "axs.set_xlabel('Team')\n",
    "axs.set_ylabel('Posterior Defensive Strength')\n",
    "_= axs.set_xticks(df_hpd.index + .5)\n",
    "_= axs.set_xticklabels(df_hpd['index'].values, rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spread of defensive strengths also appears reasonable, and once again Vegas has a slightly wider HPD as we would expect.\n",
    "\n",
    "Now let's move on to the fun part and begin trying to predict outcomes for the remaining games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduled_games = pd.read_csv('scheduled_games.csv')\n",
    "scheduled_games = scheduled_games.loc[scheduled_games['game_type'] == 'R']\n",
    "\n",
    "# Select the columns I need for this analysis\n",
    "scheduled_games = scheduled_games[['home_team', 'away_team', \n",
    "                                   'home_team_reg_score', 'away_team_reg_score', \n",
    "                                   'home_team_fin_score', 'away_team_fin_score']]\n",
    "\n",
    "scheduled_games = add_team_data_labels(scheduled_games)\n",
    "\n",
    "# Create shared theano variables that can be swapped out with\n",
    "# scheduled games later.\n",
    "home_team.set_value(scheduled_games.i_home.values)\n",
    "away_team.set_value(scheduled_games.i_away.values)\n",
    "team_pair.set_value(scheduled_games.i_pair.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    post_pred = pm.sample_ppc(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make sure that the shape of all our posterior predictions looks reasonable. There are 122 games left in the 2017-2018 Regular season, and for our posterior predictions there are 2000 samples for each game, times 122 games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scheduled_games.shape)\n",
    "print(post_pred['away_goals'].shape)\n",
    "print(post_pred['home_goals'].shape)\n",
    "print(post_pred['tie_breaker'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how these simulations play out. For simplicity I will first examine a single game; the Calgary Flames vs the San Jose Sharks in San Jose. I picked this game in particular since my father is a Flames fan, and this is the next game they will play. Let us start by looking at the predicted number of goals each team will score during regulation time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_posterior_goal_count(posterior_goals, team_name):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot()\n",
    "\n",
    "    vc = pd.Series(posterior_goals).value_counts().sort_index()\n",
    "    vc /= float(vc.sum())\n",
    "    ax = vc.plot(kind='bar', width=0.9, color='b')\n",
    "\n",
    "    ax.set_ylabel('Probability of Goal Count')\n",
    "    ax.set_xlabel('Goal Count')\n",
    "    ax.set_title('Predicted Regulation Time Goals Scored for {}'.format(team_name))\n",
    "    \n",
    "    fig = ax.get_figure()\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.show()\n",
    "\n",
    "plot_posterior_goal_count(post_pred['home_goals'][:,1], 'SJS')\n",
    "plot_posterior_goal_count(post_pred['away_goals'][:,1], 'CGY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "San Jose appears to skew a bit higher in the predicted number of regulation tie goals. As a result, we should probably expect San Jose to be more likely to win this game. Let's see what the predicted probabilities are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine all the games in which the home and away teams win, lose, \n",
    "# or tie in regulation time\n",
    "home_won_regulation = post_pred['home_goals'] > post_pred['away_goals']\n",
    "away_won_regulation = post_pred['away_goals'] > post_pred['home_goals']\n",
    "regulation_tie = post_pred['home_goals'] == post_pred['away_goals']\n",
    "\n",
    "# Determine which team utimately wins in the event of a tie\n",
    "home_won_tie_breaker = post_pred['tie_breaker'].copy()\n",
    "away_won_tie_breaker = post_pred['tie_breaker'].copy()\n",
    "home_team_is_heads = np.array([(home_team == team_pairs_heads_dict[(home_team, away_team)]) for \n",
    "                               home_team, away_team in \n",
    "                               zip(scheduled_games['home_team'], scheduled_games['away_team'])])\n",
    "home_won_tie_breaker = (home_won_tie_breaker == home_team_is_heads)\n",
    "away_won_tie_breaker = ~home_won_tie_breaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduled_game_probs = scheduled_games[['home_team', 'away_team']].copy()\n",
    "scheduled_game_probs['home_regulation_win'] = home_won_regulation.mean(axis=0)\n",
    "scheduled_game_probs['home_OT_SO_win'] = (regulation_tie & home_won_tie_breaker).mean(axis=0)\n",
    "scheduled_game_probs['away_regulation_win'] = away_won_regulation.mean(axis=0)\n",
    "scheduled_game_probs['away_OT_SO_win'] = (regulation_tie & away_won_tie_breaker).mean(axis=0)\n",
    "\n",
    "scheduled_game_probs.loc[1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The San Jose Sharks are definitely more likely to win this match according to our model. In fact, the flames have only a 49.75% chance to make it out of this game with any points. Given that the Flames are on the edge of being mathematically eliminated from a playoff spot, things aren't looking so great for their post season. Sorry Dad!\n",
    "\n",
    "Let's also look at the rest of the games the Flames are scheduled to play in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flames_home = scheduled_game_probs['home_team'] == \"Calgary Flames\"\n",
    "flames_away = scheduled_game_probs['away_team'] == \"Calgary Flames\"\n",
    "\n",
    "scheduled_game_probs.loc[(flames_home | flames_away), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to earn a playoff spot the flames would likely need to win every game left in the season, and even then that may not be enough if the teams ahead of them also play well in the mean time. The odds of the Flames winning every single game left in the season do not appear to be promising. The Flames game at home against the Arizona Coyotes is the only game where they even have a greater than 50% chance of winning the game outright, whether that is in regulation, overtime, or shootout.\n",
    "\n",
    "In the spirit of the above analysis, the next obvious step would be to look at the probability that each team will make it into the playoffs based on the predictions made for all the remaining games. Unfortunately it is not that straight forward to calculate the probability that a team will make it into the playoffs. Overall, the rules for calculating \"Wild Card\" playoff seed standings in the NHL are surprisingly convoluted. For starters, the current league is broken down into two conferences. Each conference has two divisions. The top three teams for each division earn a playoff spot. The remaining two playoff spots in each conference are then provided to the top two teams in those conferences that have not already qualified for a playoff spot. This doesn't sound too bad, except for the possibility where a tie occurs. In such a scenario, the tie breaking procedure is:\n",
    "\n",
    "\"If two or more clubs are tied in points during the regular season, the standing of the clubs is determined in the following order: The fewer number of games played (i.e., superior points percentage).The greater number of games won, excluding games won in the Shootout. This figure is reflected in the ROW column. The greater number of points earned in games between the tied clubs. If two clubs are tied, and have not played an equal number of home games against each other, points earned in the first game played in the city that had the extra game shall not be included. If more than two clubs are tied, the higher percentage of available points earned in games among those clubs, and not including any \"odd\" games, shall be used to determine the standing. The greater differential between goals for and against for the entire regular season. NOTE: In standings a victory in a shootout counts as one goal for, while a shootout loss counts as one goal against.\"\n",
    "\n",
    "While I'd love to write some sort of function to calculate these values I'm worried I'd never finish this blog post if I start down that path. At the very least I probably won't finish it before the 2017-2018 season playoffs start, at which point the predictions will not be very interesting anymore. I will leave it as a project for another day, hopefully before the start of the 2018-2019 season in October. If I'm feeling very ambitious over the next few weeks I may also try to make predictions for the playoff games once those start in April."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
